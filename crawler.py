# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import time # í¬ë¡¤ë§ ì‹œ í˜ì´ì§€ ë¡œë”©ì„ ê¸°ë‹¤ë¦¬ê¸° ìœ„í•´ ì‚¬ìš©

# Seleniu ê´€ë ¨ ëª¨ë“ˆ
from selenium.webdriver.common.by import By # ì›¹ ìš”ì†Œë¥¼ ì„ íƒí•  ë•Œ ì‚¬ìš© (CSS Selector ë“±)

# í”„ë¡œì íŠ¸ ë‚´ ëª¨ë“ˆ
from modules.webdriver import create_webdriver # Selenium WebDriverë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
from data.config import CATEGORY_URLS # ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ URLì„ ì„¤ì •í•œ ì„¤ì • íŒŒì¼
from modules.extractor import ( # ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ (í¬ë¡¤ë§í•œ ì›¹í˜ì´ì§€ì—ì„œ íŠ¹ì • ë°ì´í„°ë¥¼ ì¶”ì¶œ)
    extract_news_title, # ë‰´ìŠ¤ ì œëª©
    extract_news_content, # ë‰´ìŠ¤ ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
    extract_press_name, # ì–¸ë¡ ì‚¬(ì‹ ë¬¸ì‚¬) ì´ë¦„ ì¶”ì¶œ
    extract_news_date, # ë‰´ìŠ¤ ë°œí–‰ ë‚ ì§œ ì¶”ì¶œ
    extract_reporter_name,  # ê¸°ì ì´ë¦„ ì¶”ì¶œ
    extract_thumbnail # ë‰´ìŠ¤ ì¸ë„¤ì¼ ì´ë¯¸ì§€ URL ì¶”ì¶œ
)

# ë°ì´í„° ëª¨ë¸ ëª¨ë“ˆ
from models.news import News # í¬ë¡¤ë§í•œ ë‰´ìŠ¤ ì •ë³´ë¥¼ ê°ì²´ë¡œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤

# ì¶œë ¥ ê´€ë ¨ ëª¨ë“ˆ (í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ì •ë³´ë¥¼ ë³´ê¸° ì‰½ê²Œ ì¶œë ¥)
from modules.printer import (
    print_news_details, # í¬ë¡¤ë§í•œ ë‰´ìŠ¤ ë§í¬ ëª©ë¡ ì¶œë ¥
    print_news_links # í¬ë¡¤ë§í•œ ë‰´ìŠ¤ ê¸°ì‚¬ ìƒì„¸ ì •ë³´ ì¶œë ¥ 
)

def crawl_all_news_links(
    max_links=30 # ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ í¬ë¡¤ë§í•  ë‰´ìŠ¤ ë§í¬ ê°œìˆ˜
):
    all_news_links = {} # ëª¨ë“  ë‰´ìŠ¤ ë§í¬ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    total_news_cnt = 0 # ì „ì²´ í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ê°œìˆ˜

    # 1ì°¨ ì¹´í…Œê³ ë¦¬(primary_category)ë¥¼ ë°˜ë³µí•˜ë©°, í•˜ìœ„ 2ì°¨ ì¹´í…Œê³ ë¦¬(secondary) ì¹´í…Œê³ ë¦¬ê¹Œì§€ í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ ë§í¬ í¬ë¡¤ë§
    # "ì •ì¹˜" (1ì°¨ ì¹´í…Œê³ ë¦¬) â†’ "ë©”ì¸", "êµ­íšŒ", "ì²­ì™€ëŒ€" (2ì°¨ ì¹´í…Œê³ ë¦¬)
    for primary_category, secondary_categories in CATEGORY_URLS.items():  
        primary_category_news_cnt = 0 # í˜„ì¬ 1ì°¨ ì¹´í…Œê³ ë¦¬ì—ì„œ í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ê°œìˆ˜ 

        # ê° 2ì°¨ ì¹´í…Œê³ ë¦¬(secondary_category)ë¥¼ ìˆœíšŒí•˜ë©° ë‰´ìŠ¤ ë§í¬ë¥¼ í¬ë¡¤ë§
        for secondary_category, url in secondary_categories.items():
            if secondary_category == "ë©”ì¸": # ë©”ì¸ ì¹´í…Œê³ ë¦¬ì˜ ê²½ìš°, í—¤ë“œë¼ì¸ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰
                news_links = crawl_headline_news_links(primary_category, max_links)
            else: # ê·¸ ì™¸ì˜ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° í¬ë¡¤ë§ íŒ¨ìŠ¤ (ì¶”í›„ ìˆ˜ì •)
                news_links = []

            # í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ë§í¬ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
            all_news_links[f"{primary_category} > {secondary_category}"] = news_links
            secondary_category_news_cnt = len(news_links) # í˜„ì¬ 2ì°¨ ì¹´í…Œê³ ë¦¬ì—ì„œ í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ê°œìˆ˜
            primary_category_news_cnt += secondary_category_news_cnt # 1ì°¨ ì¹´í…Œê³ ë¦¬ì—ì„œ í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ê°œìˆ˜ ì—…ë°ì´íŠ¸
            total_news_cnt += secondary_category_news_cnt # ì „ì²´ ë‰´ìŠ¤ ê°œìˆ˜ ì—…ë°ì´íŠ¸

            # ë‰´ìŠ¤ í¬ë¡¤ë§ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥
            print(f"âœ… {primary_category} > {secondary_category} ë‰´ìŠ¤ {secondary_category_news_cnt}ê°œ í¬ë¡¤ë§ ì™„ë£Œ!") 

        # íŠ¹ì • 1ì°¨ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ ê°œìˆ˜ ì¶œë ¥
        print(f"\nğŸ“Š {primary_category} ì¹´í…Œê³ ë¦¬ ì´ {primary_category_news_cnt}ê°œ í¬ë¡¤ë§ ì™„ë£Œ!\n" + "=" * 60)

    # ì „ì²´ ë‰´ìŠ¤ ê°œìˆ˜ ì¶œë ¥
    print(f"\nğŸ¯ ì´ {total_news_cnt}ê°œì˜ ë‰´ìŠ¤ ë§í¬ í¬ë¡¤ë§ ì™„ë£Œ!\n" + "=" * 60)

    return all_news_links # í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ë§í¬ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

# ì£¼ì–´ì§„ 1ì°¨ ì¹´í…Œê³ ë¦¬ì˜ ë©”ì¸ì—ì„œ í—¤ë“œë¼ì¸ ë‰´ìŠ¤ ë§í¬ë¥¼ í¬ë¡¤ë§
def crawl_headline_news_links(
    primary_category, 
    max_links=30 # ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ í¬ë¡¤ë§í•  ë‰´ìŠ¤ ë§í¬ ê°œìˆ˜
):
    # ì£¼ì–´ì§„ 1ì°¨ ì¹´í…Œê³ ë¦¬ê°€ CATEGORY_URLSì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if primary_category not in CATEGORY_URLS:
        print(f"âŒ {primary_category} ì¹´í…Œê³ ë¦¬ëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return []
    
    driver = create_webdriver() # ì›¹ ë“œë¼ì´ë²„ ìƒì„±
    news_links = [] # í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ë§í¬ ë¦¬ìŠ¤íŠ¸
    
    try:
        category_url = CATEGORY_URLS[primary_category]["ë©”ì¸"] # í•´ë‹¹ 1ì°¨ ì¹´í…Œê³ ë¦¬ì˜ "ë©”ì¸" URL ê°€ì ¸ì˜¤ê¸°
        print(f"ğŸ” {primary_category} í—¤ë“œë¼ì¸ ë‰´ìŠ¤ í¬ë¡¤ë§ ì¤‘...") 
        driver.get(category_url) # í˜ì´ì§€ ì´ë™
        time.sleep(3) # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        
        # í—¤ë“œë¼ì¸ ë‰´ìŠ¤ ê¸°ì‚¬ ë§í¬ ê°€ì ¸ì˜¤ê¸°
        news_elements = driver.find_elements(By.CSS_SELECTOR, "a[href*='/mnews/article/']")
        for news in news_elements:
            link = news.get_attribute("href") # í•´ë‹¹ ë‰´ìŠ¤ ê¸°ì‚¬ ìš”ì†Œì˜ href ì†ì„± ì¶”ì¶œ
            # ë‰´ìŠ¤ ëŒ“ê¸€ URLì€ ì œì™¸í•˜ê³  ë‰´ìŠ¤ ê¸°ì‚¬ URLì¸ì§€ í™•ì¸
            if link and link.startswith("https://n.news.naver.com/mnews/article/") and "comment" not in link:
                if link not in news_links: # ì¤‘ë³µ ë§í¬ ë°©ì§€
                    news_links.append(link) # ë‰´ìŠ¤ ë§í¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

            if len(news_links) >= max_links:  # ìµœëŒ€ í¬ë¡¤ë§ ê°œìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ ì¢…ë£Œ
                break
        
    finally:
        driver.quit() # ì›¹ ë“œë¼ì´ë²„ ì¢…ë£Œ
        
    return news_links # í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ë§í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

# ì—¬ëŸ¬ ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ í¬ë¡¤ë§
def crawl_multiple_news_details(news_urls):
    driver = create_webdriver() # ì›¹ ë“œë¼ì´ë²„ ìƒì„±
    all_news_details = [] # ë‰´ìŠ¤ ì •ë³´ ì €ì¥ ë¦¬ìŠ¤íŠ¸

    try:
        # ì…ë ¥ëœ ë‰´ìŠ¤ URL ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° í¬ë¡¤ë§
        for url in news_urls:
            driver.get(url) # í•´ë‹¹ ë‰´ìŠ¤ í˜ì´ì§€ë¡œ ì´ë™
            
            # ë‰´ìŠ¤ ê¸°ì‚¬ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
            news_title = extract_news_title(driver) # ì œëª© ì¶”ì¶œ
            news_content = extract_news_content(driver) # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
            press_name = extract_press_name(driver) # ì‹ ë¬¸ì‚¬ ì´ë¦„ ì¶”ì¶œ
            news_date = extract_news_date(driver) # ë‰´ìŠ¤ ì‘ì„± ë‚ ì§œ ì¶”ì¶œ
            reporter_name = extract_reporter_name(driver) # ê¸°ì ì´ë¦„ ì¶”ì¶œ
            thumbnail = extract_thumbnail(driver) # ì¸ë„¤ì¼ ì´ë¯¸ì§€ URL ì¶”ì¶œ
            
            # í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ News ê°ì²´ ìƒì„±
            news = News(url, news_title, news_content, press_name, news_date, reporter_name, thumbnail)
            all_news_details.append(news) # ë‰´ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}") # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ì‹œì§€ ì¶œë ¥
    finally:
        driver.quit() # ì›¹ ë“œë¼ì´ë²„ ì¢…ë£Œ

    return all_news_details  # í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        
if __name__ == "__main__":
    # 1. ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ ë‰´ìŠ¤ ë§í¬ í¬ë¡¤ë§
    news_links = crawl_all_news_links(max_links=1) # ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ 1ê°œì˜ ë‰´ìŠ¤ ë§í¬ í¬ë¡¤ë§ (í…ŒìŠ¤íŠ¸ìš©)
    print_news_links(news_links) # í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ë§í¬ ëª©ë¡ ì¶œë ¥

    # 2. í¬ë¡¤ë§í•œ ë‰´ìŠ¤ ë§í¬ë“¤ì„ ì´ìš©í•´ ë‰´ìŠ¤ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    all_links = [link for links in news_links.values() for link in links] # í¬ë¡¤ë§ëœ ëª¨ë“  ë‰´ìŠ¤ ë§í¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    if all_links: # í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ë§í¬ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°
        print("\nğŸ“° ë‰´ìŠ¤ ê¸°ì‚¬ ìƒì„¸ ì •ë³´ í¬ë¡¤ë§ ì¤‘...")
        news_details = crawl_multiple_news_details(all_links) # ë‰´ìŠ¤ ìƒì„¸ ì •ë³´ í¬ë¡¤ë§ ìˆ˜í–‰
        print_news_details(news_details) # í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ê¸°ì‚¬ ì •ë³´ë¥¼ ì¶œë ¥
    else: # í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ë§í¬ê°€ ì—†ì„ ê²½ìš° ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
        print("âš ï¸ í¬ë¡¤ë§ëœ ë‰´ìŠ¤ ë§í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")